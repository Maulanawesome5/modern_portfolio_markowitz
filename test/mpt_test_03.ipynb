{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inisialisasi jangka waktu\n",
    "start_date = dt.datetime(year=2020, month=1, day=1)\n",
    "end_date = dt.datetime(year=2022, month=1, day=1)\n",
    "\n",
    "# akses data harga saham dari yahoo finance\n",
    "test = data.DataReader([\"PWON.JK\", \"ASRI.JK\"], \"yahoo\", start_date, end_date)\n",
    "test = pd.DataFrame(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ambil kolom harga close\n",
    "test = test[\"Close\"]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of percentage change\n",
    "pwon = test[\"PWON.JK\"].pct_change().apply(lambda x: np.log(1+x))\n",
    "pwon.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance\n",
    "var_pwon = pwon.var()\n",
    "var_pwon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of percentage change ASRI\n",
    "asri = test[\"ASRI.JK\"].pct_change().apply(lambda x: np.log(1+x))\n",
    "asri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance of asri\n",
    "var_asri = asri.var()\n",
    "var_asri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volatility\n",
    "pwon_vol = np.sqrt(var_pwon * 250)\n",
    "asri_vol = np.sqrt(var_asri * 250)\n",
    "\n",
    "pwon_vol, asri_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot volatility of both stock\n",
    "test.pct_change().apply(lambda x: np.log(1+x)).std().apply(lambda x: x * np.sqrt(250)).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of percentage\n",
    "test1 = test.pct_change().apply(lambda x: np.log(1+x))\n",
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[\"PWON.JK\"].cov(test1[\"ASRI.JK\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[\"PWON.JK\"].corr(test1[\"ASRI.JK\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log of percentage\n",
    "test2 = test.pct_change().apply(lambda x: np.log(1+x))\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights allocation\n",
    "w = [0.2, 0.8]\n",
    "e_r_ind = test2.mean()  # expected return individual\n",
    "e_r_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total expected return\n",
    "e_r = (e_r_ind * w).sum()\n",
    "e_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Optimal Risky Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = data.DataReader([\"PWON.JK\", \"ASRI.JK\", \"BBCA.JK\", \"BMRI.JK\"], \"yahoo\", start_date, end_date)\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close price\n",
    "df = df[\"Close\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = df.pct_change().apply(lambda x: np.log(1+x)).cov()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.pct_change().apply(lambda x: np.log(1+x)).corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = {\"PWON.JK\":0.1, \"ASRI.JK\":0.2, \"BBCA.JK\":0.5, \"BMRI.JK\":0.2}\n",
    "port_var = cov_matrix.mul(w, axis=0).mul(w, axis=1).sum().sum()\n",
    "port_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio expected return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly return for individual companies\n",
    "ind_er = df.resample(\"Y\").last().pct_change().mean()\n",
    "ind_er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio return\n",
    "w = [0.1, 0.2, 0.5, 0.2]\n",
    "port_er = (w * ind_er).sum()\n",
    "port_er"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Efficient Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility is given by the annual standard deviation. We multiply by 250 because there are 250 trading days/year.\n",
    "ann_sd = df.pct_change().apply(lambda x: np.log(1+x)).std().apply(lambda x: x*np.sqrt(250))\n",
    "ann_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = pd.concat([ind_er, ann_sd], axis=1) # Creating a table for visualising returns and volatility of assets\n",
    "assets.columns = ['Returns', 'Volatility']\n",
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ret = []          # Define an empty array for portfolio returns\n",
    "p_vol = []          # Define an empty array for portfolio volatility\n",
    "p_weights = []      # Define an empty array for asset weights\n",
    "\n",
    "num_assets = len(df.columns)\n",
    "num_portfolios = 100000000  # saldo Rp. 100 juta\n",
    "\n",
    "for portfolio in range(num_portfolios):\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights = weights/np.sum(weights)\n",
    "    p_weights.append(weights)\n",
    "    returns = np.dot(weights, ind_er) # Returns are the product of individual expected returns of asset and its \n",
    "                                      # weights \n",
    "    p_ret.append(returns)\n",
    "    var = cov_matrix.mul(weights, axis=0).mul(weights, axis=1).sum().sum()# Portfolio Variance\n",
    "    sd = np.sqrt(var) # Daily standard deviation\n",
    "    ann_sd = sd*np.sqrt(250) # Annual standard deviation = volatility\n",
    "    p_vol.append(ann_sd)\n",
    "\n",
    "data = {'Returns':p_ret, 'Volatility':p_vol}\n",
    "\n",
    "for counter, symbol in enumerate(df.columns.tolist()):\n",
    "    #print(counter, symbol)\n",
    "    data[symbol+' weight'] = [w[counter] for w in p_weights]\n",
    "\n",
    "portfolios = pd.DataFrame(data)\n",
    "portfolios.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22f252934ba9a100162ca5ab8c446568a02abce5ba731e5787eb00ade06eeba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
